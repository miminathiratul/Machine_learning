{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cads-logo.png\" width=200 align=left>\n",
    "<img src=\"images/python-logo.png\" width=200 align=right>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pandas\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "- [Introduction to Pandas](#Introduction-to-Pandas)\n",
    "- [Series](#Series)\n",
    "    - [Initializing Series](#Initializing-Series)\n",
    "    - [Selecting Elements](#Selecting-Elements)\n",
    "        - [loc](#loc)\n",
    "        - [iloc](#iloc)\n",
    "    - [Combining Series](#Combining-Series)\n",
    "    - [Exercises](#Exercises)\n",
    "        - [Exercise 1](#Exercise-1)\n",
    "        - [Exercise 2](#Exercise-2)\n",
    "        - [Exercise 3](#Exercise-3)\n",
    "- [DataFrames](#DataFrames)\n",
    "    - [Creating DataFrames](#Creating-DataFrames)\n",
    "        - [Series as Rows](#Series-as-Rows)\n",
    "        - [Series as Columns](#Series-as-Columns)\n",
    "        - [Summary](#Summary)\n",
    "    - [Importing and Exporting Data](#Importing-and-Exporting-Data)\n",
    "        - [Reading CSV](#Reading-CSV)\n",
    "        - [Writing CSV](#Writing-CSV)\n",
    "    - [Selecting Data](#Selecting-Data)\n",
    "    - [Exercises](#Exercises)\n",
    "        - [Exercise 1](#Exercise-1)\n",
    "        - [Exercise 2](#Exercise-2)\n",
    "        - [Exercise 3](#Exercise-3)\n",
    "        - [Exercise 4](#Exercise-4)\n",
    "- [Data Processing](#Data-Processing)\n",
    "    - [Aggregation](#Aggregation)\n",
    "    - [Arithmetic](#Arithmetic)\n",
    "    - [Grouping](#Grouping)\n",
    "    - [Unique and Duplicate Values](#Unique-and-Duplicate-Values)\n",
    "        - [unique](#unique)\n",
    "        - [duplicate](#duplicate)\n",
    "    - [Exercises](#Exercises)\n",
    "        - [Exercise 1](#Exercise-1)\n",
    "        - [Exercise 2](#Exercise-2)\n",
    "        - [Exercise 3](#Exercise-3)\n",
    "        - [Exercise 4](#Exercise-4)\n",
    "- [Merge Data Frames](#Merge-Data-Frames)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "    - [Exercise 1](#Exercise-1)\n",
    "    - [Exercise 2](#Exercise-2)\n",
    "    - [Exercise 3](#Exercise-3)\n",
    "    - [Exercise 4](#Exercise-4)\n",
    "    - [Exercise 5](#Exercise-5)\n",
    "    - [Exercise 6](#Exercise-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Pandas\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. Pandas is free software released under the three-clause BSD license. The name is derived from the term _panel data_, an econometrics term for multidimensional structured data sets.\n",
    "\n",
    "At it's core, Pandas consists of NumPy arrays and additional functions to perform typical data analysis tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "Series form the basis of Pandas. They are essentially Python dictionaries with some added bells and whistles. However, Pandas Series 'keys' are called indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Series\n",
    "Series can be initialized from Python objects like lists or tuples. If only values are given, Pandas generates default indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series also support missing values via the `None` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pandas series with None\n",
    "#observe the dtype\n",
    "animals = ['Tiger', 'Bear', None]\n",
    "print(pd.Series(animals))\n",
    "print(\"\")\n",
    "print(type(animals[0]))\n",
    "print(type(animals[1]))\n",
    "print(type(animals[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numbers = [1, 2, None]\n",
    "print(pd.Series(numbers))\n",
    "print(\"\")\n",
    "print(type(numbers[0]))\n",
    "print(type(numbers[1]))\n",
    "print(type(numbers[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define custom keys during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = pd.Series(\n",
    "    data=[\"Bhutan\", \"Scotland\", \"Japan\", \"South Korea\"], \n",
    "    index=[\"Archery\", \"Golf\", \"Sumo\", \"Taekwondo\"])\n",
    "print(sports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, Series can also be initialized with dictionaries. Indices are then generated from the dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pandas series from dictionary\n",
    "sports = pd.Series({\n",
    "    'Archery': 'Bhutan',\n",
    "    'Golf': 'Scotland',\n",
    "    'Sumo': 'Japan',\n",
    "    'Taekwondo': 'South Korea'})\n",
    "print(sports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list values and indices of series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sports.index)\n",
    "print(sports.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Elements\n",
    "As a result of iterative development of the Pandas library, there are several ways to select elements of a Series. Most of them are considered \"legacy\", however, and the best practice is to use `*.loc[...]` and `*.iloc[...]`. Take care to use the square brackets with `loc` and `iloc`, *not* the regular brackets as you would with functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loc\n",
    "Select elements by their indices. If the index is invalid, either a `TypeError` or a `KeyError` will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sports.loc['Golf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iloc\n",
    "Select elements by their numerical IDs, i.e. the n-th element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sports.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the indices were autogenerated then both loc and iloc seem to be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_noindex = pd.Series(sports.values)\n",
    "print(sports_noindex)\n",
    "print(\"\")\n",
    "print(sports_noindex.loc[0])\n",
    "print(sports_noindex.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take care to keep your code semantically correct, however. For example, if the series is resorted, the index of each element stays the same, but the ID changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_noindex_sorted = sports_noindex.sort_values()\n",
    "print(sports_noindex_sorted)\n",
    "print(\"\")\n",
    "print(sports_noindex_sorted.loc[1])\n",
    "print(sports_noindex_sorted.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to select by index then use `loc`, if you want to select by ID then use `iloc`. Do not use them interchangeably just because they return the same results right now. This will eventually lead to bugs in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Series\n",
    "Series can be combined by appending one to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([\"A\", \"B\", \"C\"])\n",
    "s2 = pd.Series([\"D\", \"E\", \"F\"])\n",
    "print(s1)\n",
    "print(\"\")\n",
    "print(s2)\n",
    "print(\"\")\n",
    "\n",
    "s3 = s1.append(s2)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the duplicate indices! Pandas permits this and selecting by `loc` will return *both* entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3.loc[0])\n",
    "print(\"\")\n",
    "print(s3.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also notice that if your selection of a Series results in a single entry, Pandas automatically converts it to its base type, i.e. a string in this case. If the selection consists of more than 1 entry, however, a Series is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3.loc[0])\n",
    "print(type(s3.loc[0]))\n",
    "print(\"\")\n",
    "print(s3.iloc[0])\n",
    "print(type(s3.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "Create a pandas Series object from the following movie ratings\n",
    "    \n",
    "    The Avengers: 9.2\n",
    "    Mr. Bean: 7.4\n",
    "    Garfield: 2.1\n",
    "    Star Wars The Force Awakens: 8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "Select the rating for the movie 'Garfield'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "Select the index of the 2$^{nd}$ entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "Multiple series with common indices can form a data frame. A data frame is like a table, with rows and columns (e.g., as in SQL or Excel).\n",
    "\n",
    "|  .   | Animal | Capital |\n",
    "| --- | --- | --- |\n",
    "| India | a | b |\n",
    "| Sweden | a | b |\n",
    "\n",
    "Each row usually denotes an entry in our data and each column a feature we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series as Rows\n",
    "Data frames can be created by glueing together Series objects as rows. In this case, the series indices become the data frame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = pd.Series((\"Elephant\", \"New Delhi\"), index=(\"Animal\", \"Capital\"))\n",
    "row2 = pd.Series((\"Reindeer\", \"Stockholm\"), index=(\"Animal\", \"Capital\"))\n",
    "print(row1)\n",
    "print()\n",
    "print(row2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[row1, row2], index=(\"India\", \"Sweden\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can make use of Pandas' flexibility and replace the Series objects with a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=[\n",
    "        {\"Animal\": \"Elephant\", \"Capital\": \"New Delhi\"},\n",
    "        {\"Animal\": \"Reindeer\", \"Capital\": \"Stockholm\"}],\n",
    "    index=(\"India\", \"Sweden\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=[[\"Elephant\", \"New Delhi\"], \n",
    "          [\"Reindeer\", \"Stockholm\"]],\n",
    "    index=[\"India\", \"Sweden\"],\n",
    "    columns=[\"Animal\", \"Capital\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to match indices and columns when combining series. Pandas won't necessarily raise an error but perform flexible merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = pd.Series((\"Elephant\", \"New Delhi\"), index=(\"Animal\", \"City\"))\n",
    "row2 = pd.Series((\"Reindeer\", \"Stockholm\"), index=(\"Animal\", \"Capital\"))\n",
    "print(row1)\n",
    "print()\n",
    "print(row2)\n",
    "df = pd.DataFrame(data=[row1, row2], index=(\"India\", \"Sweden\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series as Columns\n",
    "We can also create data frames column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = pd.Series({\"India\": \"Elephant\", \"Sweden\": \"Reindeer\"})\n",
    "col2 = pd.Series({\"India\": \"New Delhi\", \"Sweden\": \"Stockholm\"})\n",
    "print(col1)\n",
    "print()\n",
    "print(col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Animal\": col1, \"Capital\": col2})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' flexibility lets us cut out the middle man and use nested dictionaries. The keys of the outer dictionary become the column names and those of the inner dictionary become the row names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Animal\": {\n",
    "        \"India\": \"Elephant\",\n",
    "        \"Sweden\": \"Reindeer\"},\n",
    "    \"Capital\": {\n",
    "        \"India\": \"New Delhi\",\n",
    "        \"Sweden\": \"Stockholm\"}})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "Series are pasted together to become data frames. They can be pasted as:\n",
    "- rows: `data=[series1, series2, ...]`\n",
    "- columns: `data={\"Column Name 1\": series1, \"Column Name 2\": series2, ...}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same `*.index()` and `*.values()` functions as for Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index)\n",
    "print(df.columns)\n",
    "print(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Exporting Data\n",
    "Most often we don't create data within our code but read it from external sources. Pandas has a large collection of importing (and corresponding exporting) functions available.\n",
    "\n",
    "| Data | Reader | Writer |\n",
    "| --- | --- | --- |\n",
    "| CSV | `read_csv` | `to_csv` |\n",
    "| JSON | `read_json` | `to_json` |\n",
    "| HTML | `read_html` | `to_html` |\n",
    "| Local clipboard | `read_clipboard` | `to_clipboard` |\n",
    "| Excel | `read_excel` | `to_excel` |\n",
    "| HDF5 | `read_hdf` | `to_hdf` |\n",
    "| Feather | `read_feather` | `to_feather` |\n",
    "| Parquet | `read_parquet` | `to_parquet` |\n",
    "| Msgpack | `read_msgpack` | `to_msgpack` |\n",
    "| Stata | `read_stata` | `to_stata` |\n",
    "| SAS | `read_sas` |  |\n",
    "| Python Picke Format | `read_pickle` | `to_pickle` |\n",
    "| SQL | `read_sql` | `to_sql` |\n",
    "| Google Big Query | `read_gbq` | `to_gbq` |\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading CSV\n",
    "We will read a tabular CSV file as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/cars.csv\")\n",
    "cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define one of the columns as an index column using either the column header (if it exists) or the column ID (remember, Python starts counting at 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/cars.csv\", index_col=\"model\")\n",
    "# Use head() to print only the first few lines\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/cars.csv\", index_col=0)\n",
    "cars.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing CSV\n",
    "Writing CSV files is as straightforward as it gets. Notice that these functions are now methods of the specific objects, not of base Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "# For windows:\n",
    "# !dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.to_csv(\"cars2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.to_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Data\n",
    "Selecting data from Pandas arrays works just as it did for NumPy arrays, except that `loc` and `iloc` are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.iloc[4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.iloc[1:9:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with Series, we can also select items by their index names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.loc[\"Datsun 710\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.loc[[\"Datsun 710\", \"Ferrari Dino\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how a single entry is shown as a series but multiple entries as a data frame. This is analogous to how a single entry of a series is shown as a base type and multiple entries as a smaller series\n",
    "\n",
    "<br><center><b>Base Type --> Series --> Data Frame</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting columns can be done just as with dictionaries except that we can select multiple Pandas columns simultaneously. As with row selection, selecting a single column results in a Series object but selecting multiple columns results in a new DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"disp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[[\"disp\", \"wt\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also use the `*.loc`/`.*iloc` syntax. In this case, we have to include both the row and column indices to select. As with base Python, the color `:` instructs Pandas to select all rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.loc[:, \"disp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.loc[\"Mazda RX4\", \"disp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note that if we want to mix ID and index selection, we need to chain together `loc` and `iloc` calls. There is no way to combine this into a single index tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cars.iloc[4])\n",
    "print()\n",
    "print(cars.iloc[4].loc[\"mpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cars.loc[:, \"mpg\"])\n",
    "print()\n",
    "print(cars.loc[:, \"mpg\"].iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the names of all columns with the `columns` property (notice that this is also an index object, just as the row names is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cars.columns)\n",
    "print(cars.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use boolean masks to select rows or columns, i.e.\n",
    "\n",
    "```python\n",
    "cars.loc[True, True, False, True, False, ...]\n",
    "```\n",
    "\n",
    "However, as we're dealing with large datasets, typing them out by hand is suboptimal. So let's use some simple boolean conditions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas applies the operation to each individual entry\n",
    "print(cars[\"mpg\"] > 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc, not iloc, to select based on boolean masks\n",
    "cars.loc[cars[\"mpg\"] > 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select specific rows of certain columns with boolean masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.loc[cars[\"mpg\"] > 25, [\"hp\", \"disp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.iloc[5, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "Familiarize yourselves with data frame creation and handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "Manually create a dataframe from the following data. EmployeeID should be the index of the dataframe.\n",
    "```\n",
    "EmployeeID,EmployeeName,Salary,Department\n",
    "2044,James,2500,Finance\n",
    "1082,Hannah,4000,Sales\n",
    "7386,Victoria,3700,IT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "Read in the chocolate.csv data set and display the first 8 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "Select only the chocolates with \"Congo\" as the country of origin and show only the rating, the cocoa percent, and the country of origin (to make sure we've selected the right products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "Oh no! There was a mistake in the data entry. One of the products has a missing country of origin. Please find it, replace it with \"Venezuela\", and save the fixed data frame as \"chocolate_fixed.csv\"\n",
    "\n",
    "  - You can use `*.isna()` to identify which entry of a series is either `NaN` or `None`, e.g. `mySeries.isna()`\n",
    "  - You can assign values to data frames just like you would to lists, e.g. `df.iloc[0, 5] = 15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choc.loc[choc[\"Country of Origin\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Pandas contains many functions to process and transform data. These can be called either on data frames or individual series. Describing every function in detail is far too time-consuming and application-dependent. A thorough list and description of *all* Pandas functionality can be found here: https://pandas.pydata.org/pandas-docs/stable/api.html\n",
    "\n",
    "Many of the functions are more or less self-explanatory and/or well-documented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = pd.Series([1, 2, 3, 4, 5, 5, 6, 6, 6])\n",
    "print(numbers.sum())\n",
    "print(numbers.mean())\n",
    "print(numbers.max())\n",
    "print(numbers.min())\n",
    "print(numbers.idxmax())\n",
    "print(numbers.idxmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions can be applied to series or data.frames. In the case of data frames, they are applied to each row or column individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,1,1], [2,2,2], [3,3,3]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide whether the aggregation should occur along columns or rows. Note however, that the syntax is confusing. `axis=X` indicates along which dimension the function will \"travel\". For example, `axis=columns` indicates that all columns will be collapsed into the function, and the function will be applied to individual rows. Likewise, `axis=rows` means that the function will travel along rows and compute the aggregate value for each column individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important aggregation function is `*.apply()`, which applies an arbitrary function to each row/column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: sum(x**2), axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`*.apply()` is slower than the built-in functions, so should not be used for simple operations that can also be solved with direct operations on data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,1,1], [2,2,2], [3,3,3]])\n",
    "\n",
    "%timeit df.apply(lambda x: sum(x**2))\n",
    "%timeit (df**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also take care that the function will be applied to all columns, regardless of type. The built-in functions are clever enough to skip columns for which they are not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Age\": [10, 12, 12], \n",
    "    \"Name\": [\"Liz\", \"John\", \"Sam\"]})\n",
    "df.sum()\n",
    "\n",
    "# Uncomment for exception\n",
    "#df.apply(lambda x: sum(x**2), axis=\"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic\n",
    "We can also perform element-wise operations on dataframe columns or rows, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=[[1,2,3], [4,5,6], [7,8,9]], \n",
    "    columns=[\"ColA\", \"ColB\", \"ColC\"], \n",
    "    index=[\"RowA\", \"RowB\", \"RowC\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ColA\"] + df[\"ColB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is smart enough to convert our list into a series and then add the two columns element-wise\n",
    "df[\"ColA\"] + [10, 11, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, both rows AND columns can be represented as Pandas series\n",
    "df.loc[\"RowA\"] * df.loc[\"RowB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "A core functionality of Pandas is the ability to group data frames and apply functions to each individual group. The function `*.groupby(...)` defines groups based on common labels. Aggregators applied to this grouped data frame are then applied to each group individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Height\": [178, 182, 158, 167, 177, 174, 175, 185], \n",
    "    \"Age\": [24, 33, 32, 18, 21, 28, 22, 29],\n",
    "    \"Gender\": [\"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"F\"]})\n",
    "display(df)\n",
    "print(df.groupby(\"Gender\"))\n",
    "display(df.groupby(\"Gender\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Height\": [178, 182, 158, 167, 177, 174, 175, 185], \n",
    "    \"Age\": [24, 33, 32, 18, 21, 28, 22, 29],\n",
    "    \"Gender\": [\"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"F\"]})\n",
    "df.groupby('Gender').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select columns without disturbing the grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby(\"Gender\")[\"Height\"])\n",
    "display(df.groupby(\"Gender\")[\"Height\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful function is `size()`, which counts how large each of the groups is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Gender\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique and Duplicate Values\n",
    "Two functions can help us identify unique and duplicate values within Series objects. They are aptly names `unique()` and `duplicate()`, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unique\n",
    "`*.unique()` returns only unique values of a Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,2,3,4,3,5])\n",
    "s.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### duplicate\n",
    "`*.duplicated()` identifies duplicated values in Series objects and returns a boolean Series. Entries that have already been seen are marked as `True` while new values are marked as `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,2,3,4,3,5])\n",
    "s.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applied to Dataframes, `duplicated()` compares entire rows for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    [\"Dog\", 5], \n",
    "    [\"Cat\", 4], \n",
    "    [\"Dog\", 5], \n",
    "    [\"Fish\", 2], \n",
    "    [\"Cat\", 8]], \n",
    "    columns=[\"Animal\", \"Age\"])\n",
    "display(df)\n",
    "display(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove duplicate rows from a data frame we could therefore do the following (just like in NumPy, booleans are negated with `~`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "Load the \"cars.csv\" dataframe and calculate the average miles per gallon (column \"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "Cars can have 4, 6, or 8 cylinders (column \"cyl\"). Find the mean miles per gallon (column \"mpg\") for each of these classes **without** using the `groupby(...)` function.\n",
    "\n",
    "*BONUS: Write a function that takes the number of cylinders and returns the mean miles per gallon.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "Repeat the above exercise but this time make use of the `groupby(...)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "Your client has a proprietary metric for car engine quality that is calculated as $Q = \\frac{hp}{wt^2}$. Calculate this metric for all cars and then find the average for cars with a manual (column \"am\" == 1) or automatic (column \"am\" == 0) transmission.\n",
    "\n",
    "**HINT** You can add the new metric as a column to your data frame via `cars[\"q_metric'] = ...`. Assignments to unknown column (or row) index names will result in new columns (or rows) to be appended to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data Frames\n",
    "Pandas data frames can be treated like SQL tables and joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.DataFrame({\n",
    "    \"Date\": pd.date_range(start=\"2018-10-01\", end=\"2018-10-07\"), \n",
    "    \"ItemID\": [\"A401\", \"C776\", \"A401\", \"FY554\", \"Y98R\", \"Y98R\", \"FY554\"]})\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info = pd.DataFrame({\n",
    "    \"ID\": [\"A401\", \"C776\", \"FY554\", \"Y98R\"],\n",
    "    \"Name\": [\"Toaster\", \"Vacuum Cleaner\", \"Washing Machine\", \"Clothes Iron\"], \n",
    "    \"Price\": [25, 220, 540, 85]})\n",
    "item_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.merge(right=item_info, how=\"inner\", left_on=\"ItemID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge types:\n",
    "- **Inner**: keep only rows with corresponding IDs found in *both* data frames\n",
    "- **Left**: use only rows with IDs found in the left data frame\n",
    "- **Right**: use only rows with IDs found in the right data frame\n",
    "- **Outer**: use all keys that are in at least one of the data frames. This is essentially the combination of left and right joins\n",
    "\n",
    "Missing data will be replaced by `NaN` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.DataFrame({\n",
    "    \"Date\": pd.date_range(start=\"2018-10-01\", end=\"2018-10-07\"), \n",
    "    \"ItemID\": [\"A401\", \"ZZZC776\", \"A401\", \"ZZZFY554\", \"Y98R\", \"Y98R\", \"FY554\"]})\n",
    "display(sales)\n",
    "item_info = pd.DataFrame({\n",
    "    \"ID\": [\"A401\", \"C776\", \"FY554\", \"Y98R\", \"U1776\"],\n",
    "    \"Name\": [\"Toaster\", \"Vacuum Cleaner\", \"Washing Machine\", \"Clothes Iron\", \"Computer\"], \n",
    "    \"Price\": [25, 220, 540, 85, 899]})\n",
    "display(item_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.merge(right=item_info, how=\"inner\", left_on=\"ItemID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.merge(right=item_info, how=\"left\", left_on=\"ItemID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.merge(right=item_info, how=\"right\", left_on=\"ItemID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.merge(right=item_info, how=\"outer\", left_on=\"ItemID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also merge on indices, either of one or both of the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index(\"employee\")\n",
    "df2 = df2.set_index(\"employee\")\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "df2 = df2.set_index(\"employee\")\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, left_on=\"employee\", right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "A large part of our task as data scientists and analysts is to find patterns and interesting phenomena within data. We can make use of Pandas' vast assortment of functions to help us with this. The following exercises are designed to help you get an idea of the kind of questions you can answer with Pandas.\n",
    "\n",
    "This dataset describes all olympic athletes, the year they participated, the event they participated in, and whether they received a medal. The data is split into two files, `olympics_events.csv` and `olympics_games.csv`, describing the events and metadata of the games, respectively. The data has been adjusted from https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "1. Load the two files, `olympics_events.csv` and `olympics_games.csv`, and display the first 10 lines of each data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Merge the two data frames on the `GamesID` and `ID` columns. Drop the now-unnecessary id-columns afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "History lesson! Malaysia's olympic nationality code is `MAS`. Prior to this, the Federation of Malaya competed under the code `MAL`. Likewise, Sarawak and Sabah competed as North Borneo (`NBO`).\n",
    "\n",
    "1. In which years did the Federation of Malaya compete in the Olympics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many athletes did they send?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.loc[events[\"Nationality\"] == \"MAL\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Who were the first countries to participate in the Olympic games (as per this data set)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_event = events.loc[events[\"Year\"] == earliest_year]\n",
    "first_event.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = first_event[\"Nationality\"].unique()\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How many men and women has Malaysia (`MAS`) sent to the Olympics in total? Keep in mind that athletes can participate in multiple events and multiple years. Each person should only ever be counted once.\n",
    "\n",
    "*HINT*: As we're only interested in athlete names and their genders, it's easiest to drop other columns and not have to worry about them. Create a new data frame but don't overwrite `events` as we'll need it for later exercises as well, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "1. How many men and women has Malaysia (`MAS`) sent to the Olympics each year?\n",
    "\n",
    "    Hint: This is a lot like the previous question except that athletes only count as duplicate now if they compete in multiple events in the same year. An athlete competing in multiple years is no longer duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes_mas.drop_duplicates(['Year', 'Name']).groupby('Year').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How does the ratio of male to female athletes sent by Malaysia compare to the global ratio for the year 2016?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Let's start looking at some of the numerical data!\n",
    "\n",
    "1. How many gold medals has each country won? How about Malaysia (`MAS`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "1. What is the median age of gold medalists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the median age of gold, silver, and bronze medalists for each individual sport?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Look at only swimmers. How has the mean weight of all competitors changed throughout the years? Use `*.plot()` to get a visual sense of the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the mean and standard deviation of the BMI of athletes in each sports discipline? The BMI can be computed as \n",
    "\n",
    "    $$BMI = Weight~/~\\left(\\frac{Height}{100}\\right)^2$$\n",
    "\n",
    "    with the values in this dataset. To solve this question, break it down into individual steps:\n",
    "    - Calculate the BMI for all athletes\n",
    "    - Group by 'Sport'\n",
    "    - Calculate the mean and standard deviation of the BMI of the grouped data frame\n",
    "    \n",
    "    *Hint*: Use `*.agg([..., ...])` to apply \"mean\" and \"std\" (standard deviation) simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "1. What country has the most gold medals in wrestling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many different types of events have ever been held for fencing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Typically, only one of each medal is awarded per year for each event. This is not the case for team sports, however. If a team wins the gold, then each team member is awarded a gold medal. What is the largest team to have ever been awarded gold medals for a single event in a single year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learn more**:  \n",
    "* [Pandas Documentation](http://pandas.pydata.org/pandas-docs/stable/index.html), especially\n",
    "[10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "* Pandas Tutorials from Tom Augspurger, one of Pandas core developers:\n",
    "    - [Pandas Head to Tail](https://github.com/TomAugspurger/pydata-chi-h2t)\n",
    "    - [Effective Pandas](https://github.com/TomAugspurger/effective-pandas) \n",
    "* [Harvard CS109 lab1 content](https://github.com/cs109/2015lab1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
